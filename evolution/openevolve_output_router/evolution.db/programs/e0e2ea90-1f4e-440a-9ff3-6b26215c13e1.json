{"id": "e0e2ea90-1f4e-440a-9ff3-6b26215c13e1", "code": "from __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom symprompt.router.features import PromptFeatures, extract_features\nfrom symprompt.symil.profiles import SymILProfile, get_profile\n\n\n@dataclass\nclass RoutingDecision:\n    tier: int\n    symil_level: int\n    profile_name: str\n    preferred_solver: str = \"z3\"\n\n\nclass SmartRouter:\n    \"\"\"\n    Heuristic router that selects tier, SymIL level, and profile based on\n    prompt features. The thresholds and mapping are intended to be evolved\n    by OpenEvolve in later phases.\n    \"\"\"\n\n    def route(self, prompt: str, context) -> RoutingDecision:\n        features: PromptFeatures = extract_features(prompt)\n\n        profile: SymILProfile = get_profile(features.domain)\n\n        # BYPASS: pure LLM path for very simple, non-logical prompts.\n        # Do not bypass when math keywords are present.\n        if (\n            not features.has_logic_keywords\n            and not features.has_numbers\n            and features.complexity < 0.2\n        ):\n            return RoutingDecision(\n                tier=0,\n                symil_level=0,\n                profile_name=profile.name,\n                preferred_solver=\"z3\",\n            )\n\n\n\n        if features.complexity < 0.25 and features.logical_depth < 2:\n            tier = 1\n            symil_level = 0\n        elif features.complexity < 0.8 and features.constraint_count < 5:\n            tier = 1\n            symil_level = 1\n        else:\n            tier = 2\n            symil_level = 2\n\n        return RoutingDecision(\n            tier=tier,\n            symil_level=symil_level,\n            profile_name=profile.name,\n            preferred_solver=profile.preferred_solver,\n        )\n", "language": "python", "parent_id": "9ebb97f2-ef3a-4838-ba8a-68b2af46262c", "generation": 1, "timestamp": 1764607217.273736, "iteration_found": 1, "metrics": {"combined_score": 0.7244186046511628, "tier1_accuracy": 0.6744186046511628, "tier2_accuracy": 0.0, "syntactic_validity": 0.8488372093023255, "tier1_p95_latency_ms": 11.77541702054441, "tier2_p95_latency_ms": 0.0, "routing_score": 0.5930232558139535, "latency_score": 1.0, "evaluation_time_ms": 371185.59562496375}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 7 lines with \nChange 2: Replace 9 lines with 9 lines", "parent_metrics": {"combined_score": 0.6581395348837209, "tier1_accuracy": 0.6627906976744186, "tier2_accuracy": 0.0, "syntactic_validity": 0.8255813953488372, "tier1_p95_latency_ms": 18.91941699432209, "tier2_p95_latency_ms": 0.0, "routing_score": 0.4418604651162791, "latency_score": 1.0, "evaluation_time_ms": 889609.9502090365}, "island": 0}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}
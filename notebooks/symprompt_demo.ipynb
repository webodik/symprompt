{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymPrompt Demo\n",
    "\n",
    "SymPrompt is a two-tier neuro-symbolic framework for translating natural language prompts into formal symbolic representations (SymIL) and verifying them with solvers.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Basic syllogistic reasoning\n",
    "2. Multi-domain examples (math, planning, legal)\n",
    "3. The routing system and tier selection\n",
    "4. SymIL representation inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - import required modules\n",
    "from symprompt.integration.router_adapter import route_and_solve\n",
    "from symprompt.llm.sync_client import build_default_sync_client\n",
    "from symprompt.router.smart_router import SmartRouter\n",
    "from symprompt.translation.pipeline import TranslationPipeline\n",
    "\n",
    "# Initialize components\n",
    "llm_client = build_default_sync_client()\n",
    "router = SmartRouter()\n",
    "pipeline = TranslationPipeline.from_llm_client(llm_client)\n",
    "\n",
    "print(\"SymPrompt initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Syllogistic Reasoning\n",
    "\n",
    "Classic categorical syllogisms are the foundation of formal logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic Socrates syllogism\n",
    "prompt = \"All men are mortal. Socrates is a man. Is Socrates mortal?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"\\nRouting Decision:\")\n",
    "print(f\"  Tier: {result.routing.tier}\")\n",
    "print(f\"  Profile: {result.routing.profile_name}\")\n",
    "print(f\"  SymIL Level: {result.routing.symil_level}\")\n",
    "print(f\"\\nSolver Result: {result.solver_result.get('status')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the SymIL representation\n",
    "if result.symil:\n",
    "    print(\"SymIL Representation:\")\n",
    "    print(f\"\\nFacts:\")\n",
    "    for fact in result.symil.facts:\n",
    "        print(f\"  {fact}\")\n",
    "    print(f\"\\nRules:\")\n",
    "    for rule in result.symil.rules:\n",
    "        print(f\"  {rule}\")\n",
    "    print(f\"\\nQuery: {result.symil.query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid syllogism - affirming the consequent fallacy\n",
    "prompt = \"All cats are mammals. Fido is a mammal. Is Fido a cat?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")\n",
    "print(f\"(Expected: NOT_VALID - this is the affirming the consequent fallacy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mathematical Reasoning\n",
    "\n",
    "SymPrompt handles mathematical relationships using Z3 solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transitive inequality\n",
    "prompt = \"If x > y and y > z, then x > z. x is 5, y is 3, z is 1. Is x greater than z?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Profile: {result.routing.profile_name}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid mathematical inference\n",
    "prompt = \"a is greater than b. c is greater than d. Is a greater than d?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")\n",
    "print(f\"(Expected: NOT_VALID - no transitive chain between a and d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Planning Domain\n",
    "\n",
    "Planning problems involve preconditions, actions, and effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple precondition check\n",
    "prompt = \"To open a door, you need a key. Alice has a key. Can Alice open the door?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Profile: {result.routing.profile_name}\")\n",
    "print(f\"Tier: {result.routing.tier}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource constraint\n",
    "prompt = \"Building a house requires 100 bricks. We have 50 bricks. Can we build a house?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")\n",
    "print(f\"(Expected: NOT_VALID - insufficient resources)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Legal/Deontic Reasoning\n",
    "\n",
    "Legal reasoning involves obligations, permissions, and prohibitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permission\n",
    "prompt = \"Adults are permitted to vote. Sarah is an adult. Is Sarah permitted to vote?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Profile: {result.routing.profile_name}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception handling\n",
    "prompt = \"All vehicles must pay tolls, except emergency vehicles. An ambulance is an emergency vehicle. Must an ambulance pay tolls?\"\n",
    "\n",
    "result = route_and_solve(prompt, llm_client)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Tier: {result.routing.tier}\")\n",
    "print(f\"Solver Result: {result.solver_result.get('status')}\")\n",
    "print(f\"(Expected: NOT_VALID - exception applies)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Evaluation\n",
    "\n",
    "Run multiple prompts and check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    (\"All birds can fly. Tweety is a bird. Can Tweety fly?\", \"VALID\"),\n",
    "    (\"All squares are rectangles. This shape is a rectangle. Is it a square?\", \"NOT_VALID\"),\n",
    "    (\"If it rains, the ground is wet. It rained. Is the ground wet?\", \"VALID\"),\n",
    "    (\"Some dogs are friendly. Max is a dog. Is Max friendly?\", \"NOT_VALID\"),\n",
    "]\n",
    "\n",
    "correct = 0\n",
    "for prompt, expected in test_cases:\n",
    "    result = route_and_solve(prompt, llm_client)\n",
    "    actual = result.solver_result.get('status')\n",
    "    match = \"OK\" if actual == expected else \"MISMATCH\"\n",
    "    if actual == expected:\n",
    "        correct += 1\n",
    "    print(f\"[{match}] {prompt[:50]}...\")\n",
    "    print(f\"    Expected: {expected}, Got: {actual}\")\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{len(test_cases)} ({100*correct//len(test_cases)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Router Feature Extraction\n",
    "\n",
    "Inspect how the router classifies prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symprompt.router.smart_router import SmartRouter\n",
    "\n",
    "router = SmartRouter()\n",
    "\n",
    "prompts = [\n",
    "    \"All mammals are animals. Dogs are mammals. Are dogs animals?\",\n",
    "    \"x + y = 10. x = 3. What is y?\",\n",
    "    \"To bake a cake, you need flour. We have flour. Can we bake?\",\n",
    "    \"Employees must report by 9am. John arrived at 8:30am. Did John comply?\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    decision = router.route(prompt)\n",
    "    print(f\"Prompt: {prompt[:50]}...\")\n",
    "    print(f\"  -> Tier: {decision.tier}, Profile: {decision.profile_name}, Level: {decision.symil_level}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "SymPrompt provides:\n",
    "- **Two-tier routing**: Fast path (Tier 1) for simple logic, full pipeline (Tier 2) for complex reasoning\n",
    "- **Multi-domain support**: Syllogism, math, planning, legal, and more\n",
    "- **SymIL representation**: Structured intermediate language for formal reasoning\n",
    "- **Multiple solvers**: Z3, Clingo (ASP), Scallop, VSA\n",
    "\n",
    "For more information, see the architecture documentation in `docs/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

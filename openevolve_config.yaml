max_iterations: 200
checkpoint_interval: 20
log_level: "INFO"
random_seed: 42
max_code_length: 20000

llm:
  # Using LiteLLM backend; actual model configured via SYMPROMPT_LLM_MODEL or here.
  primary_model: "openrouter/x-ai/grok-4.1-fast:free"
  temperature: 0.7
  max_tokens: 8192
  timeout: 900
  retries: 10
  retry_delay: 5

prompt:
  template_dir: "symprompt/evolution/prompts"
  system_message: "system_message"
  evaluator_system_message: "system_message"
  num_top_programs: 3
  num_diverse_programs: 2
  include_artifacts: true

database:
  db_path: "evolution/openevolve_output/evolution.db"
  in_memory: false
  population_size: 20
  archive_size: 20
  num_islands: 1
  migration_interval: 10
  migration_rate: 0.1
  feature_dimensions:
    - "complexity"
    - "combined_score"
  feature_bins: 8
  random_seed: 42
  log_prompts: true

evaluator:
  enable_artifacts: true
  cascade_evaluation: false
  timeout: 900
  parallel_evaluations: 10

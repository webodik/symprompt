max_iterations: 200
checkpoint_interval: 20
log_level: "INFO"
random_seed: 42
max_code_length: 20000

llm:
  # Using LiteLLM backend; actual model configured via SYMPROMPT_LLM_MODEL or here.
  primary_model: "openrouter/x-ai/grok-4.1-fast:free"
  temperature: 0.5
  timeout: 120
  retries: 3
  retry_delay: 5

prompt:
  template_dir: "symprompt/evolution/prompts"
  system_message: "system_message"
  evaluator_system_message: "system_message"
  num_top_programs: 3
  num_diverse_programs: 2
  include_artifacts: true

database:
  db_path: "evolution/openevolve_output/evolution.db"
  in_memory: false
  population_size: 20
  archive_size: 20
  num_islands: 1
  migration_interval: 10
  migration_rate: 0.1
  feature_dimensions:
    - "complexity"
    - "syllogism_accuracy"
    - "math_accuracy"
    - "planning_accuracy"
    - "legal_accuracy"
  feature_bins: 8
  random_seed: 42
  log_prompts: true

evaluator:
  timeout: 300
  max_retries: 2
  cascade_evaluation: false
  parallel_evaluations: 4
  use_llm_feedback: false
  llm_feedback_weight: 0.1
